\documentclass[a4paper,10pt,twocolumn]{article} %{{{1
%\documentclass[a4paper,10pt]{article} 
\usepackage[utf8]{inputenc}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}

\usepackage{epsfig} %for Ã¥ lime inn filer

\usepackage{algorithmic}
\usepackage{algorithm}  
%\usepackage{babel}  

\newcommand{\ts}[1]{\textbf{#1}}
\newcommand{\bra}[1]{\langle{#1}|}
\newcommand{\ket}[1]{|#1\rangle{}}
%\newcommand{\braket}[1][2]{\langle{#1}|#2\rangle{}}
\newcommand{\abs}[1]{\left|{#1}\right|}
\newcommand{\expec}[1]{\langle{}{#1}\rangle{}}

%Define theorem enviroment. 
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{assumption}[theorem]{Assumption}


\newenvironment{proof}[1][Proof]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}
\newenvironment{definition}[1][Definition]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}
\newenvironment{example}[1][Example]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}
\newenvironment{remark}[1][Remark]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}
\newcommand{\qed}{\nobreak \ifvmode \relax \else
      \ifdim\lastskip<1.5em \hskip-\lastskip
      \hskip1.5em plus0em minus0.5em \fi \nobreak
      \vrule height0.75em width0.5em depth0.25em\fi} %}}}1

\title{ Project 1, Fys 4411 \\ }
\author{Karl R. Leikanger}

\begin{document}

\maketitle
\tableofcontents

\begin{abstract}%{{{1
blablabla
\end{abstract}%}}}1

\section{Quantum dots}% {{{1

Our system of choice 

%}}}1

\section{The Monte Carlo method}%{{{1

\subsection{Introduction}%{{{2
Monte Carlo (MC) methods includes a wide range of computational methods for solving integrals. 
The main idea is to sample the integrand $f(\ts r)$ in random points $\{\ts r_i\}$, 
and finding an approximate solution to the integral by doing statistical analysis on the sampling data. 
The statistical error will give us an immediate idea of the precision of the result.
%Statistical measures will give us an idea of the quality of the results

In general, any integral can be written on the form
\begin{align}
\int_{\mathcal D} f(\ts r) d\ts r = 
\int_{\mathcal D} P(\ts r) g(\ts r) d\ts r,
\end{align} 
where $P(\ts r)$ is a probability distribution. The integral can now be approximated by the sum 
\begin{align}
	\int_{\mathcal D} f(\ts r) d\ts r 
\approx \frac1N\sum_{i=1}^Ng(\ts r_i),
\end{align} 
where $\{\ts r_i\}$ is a set of random numbers drawn from the statistical distribution $P(\ts r)$.

The simplest example, possible whenever the region of the of the integral is finite,
is when $P$ is a uniform distribution bounded by the integration limits. Then
$P(\ts r)$ is a constant and $g(\ts r)=f(\ts r)$. However, for many integrals this method 
will converge slowly and will require a very large number of samples to
give accurate results. By choosing a smart $P(\ts r)$ that is large in the regions of interest, 
%for example where $g(\ts r)$ is large or changing rapidly,  
more samples will be drawn from the important regions, often leading to a more rapid convergence.  
%}}}2

\subsection{Markov Chain Monte Carlo}%{{{2

Markov Chain Monte Carlo (MCMC) provides us with a method for drawing the correct samples from $P$. 
Instead of drawing uncorrelated random samples we use a markow chain to generate a sequence $\{\ts r_n\}$ of vectors.
A Markov chain is characterized by a transition kernel $q(\ts x|\ts y)$ which is a probability density distribution 
of the variable $\ts y$, and which tells us the probability of a transition from $\ts x$ to $\ts y$.
For each $\ts r_n$, we draw a new $\ts r_{n+1}$ from the distribution $q(\ts r_n,\ts y)$. The distribution 
of the vectors in the set 
$\{\ts r_n\}$ will converge towards the distribution $P$ if the following 
conditions are fulfilled (reference):
\begin{itemize}
\item
	$P$ is an invariant of the kernel $q(\ts x|\ts y)$ in the sense that 
	\begin{align}
	\int_{\mathcal D} d\ts r_A\, P(\ts r_A) q(\ts r_A | \ts r_B) = P(\ts r_B) \label{eq221},
	\end{align}
\item
	The chain is ergodetic, which means that any point $\ts r_n$ is accessible in a finite number transitions from any starting point $\ts r_0$. 
%	\begin{align}
%		0>&q(r_0|r_1)q(r_1|r_2)\dots q(r_{n-1}|r_n),\notag\\
%		&\{r_0,r_1,\dots,r_n\}\in\mathcal D 
%	\end{align}
%	for all $r_n$ in the integration domain. 	
%	(more?reference!)
%all $\vec r$ in $\mathcal D$% must be axessible to a random walker
%starting in any point $\vec r_0$ in $\mathcal D$ during a finite number of transitions. 
\end{itemize}

%More sophisticated methods exist, like the Metropolis-Hastings algorithm, where the drawing process is biased.
%To compensate for the biased 
%This method has the drawback that the samples are correlated which makes the analysis of the results somewhat more demanding. But the method also has
%some important advantages. One of them, as we will see later, is that the probabilityfunction $P$ does not need to be normalised. 
%This property comes very handy when dealing with many-particle wavefunctions in quantum mechanics.
%
%$P$ is sampled by generating a random new $\vec r_i$. The new position is then accepted by a probability 
%
%Both statements are actually quite intuitive, and i will now explain why(rewrite sentence):
It is costumary to make the analogy to a set of $\lambda$ biased random walkers, where
the density of walkers $P_w$ is (close to) stationary and proportional to $P$.
This analogy is reasonable as long as the sequence $\{\ts r_n\}$ can be split into $\lambda$ 
subsequences $\{\ts r_n^\lambda\}$ which are (practically speaking) uncorrelated. Then one can equally well interpret the samples as $N$ samples
from one markov chain, as $N/\lambda$ samples from $\lambda$ markov chains.

For $P_w$ to be stationary (), the population of walkers in any point $\ts r_A$ must be () constant,
\begin{align}
	\sum_n P_w(\ts r_A) q(\ts r_A|\ts r_n)  \approx	\sum_n P_w(\ts r_n) q(\ts r_n|\ts r_A) \label{eq222}
\end{align} 
This equation resembles('') (\ref{eq221}) since both equations states that the density is stationary.
%Of course, in a computer simulation the number of walkers is finite, and this equation can only be seen as an approximation.
%The markov chain must also be ergodetic. 
%One are free to choose any equation for the trajectories of the random walkers (any transition kernel) as long as (\ref{eq222})
The condition of detailed balance
\begin{align}
    P_w(\ts r_A) q(\ts r_A|\ts r_B)  =  P_w(\ts r_B) q(\ts r_B|\ts r_A).\label{detbal}
\end{align}
assures that (\ref{eq222}) is fulfilled. 
%This equation is the basis for finding the transition kernels that is used in the metropolis-Hastings algorithm.
As long as the markow chain is ergodetic the walkers will have access to all regions of the integration domain.
% ad the entire integration domain will be sampled.
%If not (ergodetic in regions: can be tackled ? )
%}}}2

\subsection{Metropolis-Hasting algorithm}%{{{2
We will now outline a general algorithm for the movement of the random walkers that fulfills (\ref{detbal}).
We introduce new scalar field to our equation $\gamma(\ts r_A,\ts r_B)$, which is a measure of the 
probability of accepting a move from $\ts r_A$ to $\ts r_B$.
We split our transition kernel in two parts
\begin{align}
	q(\ts r_A|\ts r_b) 
		\to 
	\gamma(\ts r_A|\ts r_b)
	g(\ts r_A|\ts r_b).
\end{align} 
I will refer to $g(r_A|r_B)$ as the suggestion density, and $\gamma(\ts r_A|\gamma \ts r_B)$ as the acceptance probability. We set
\begin{align}
&\gamma(\ts r_B|\ts r_A)=1 \text{ when }\notag\\
%\begin{align}
    &P_w(\ts r_A) g(\ts r_A|\ts r_B)  >  P_w(\ts r_B) g(\ts r_B|\ts r_A).
\end{align}
Then, by inserting this equations into (\ref{detbal}), we get
\begin{align} 
	\gamma(\ts r_A|\ts r_B)=min\left(
	\frac
	{P_w(\ts r_B) g(\ts r_B|\ts r_A)}
    {P_w(\ts r_A) g(\ts r_A|\ts r_B)}\, 
	,\, 1 \right) \label{gamma}
\end{align}
By making this choice for $\gamma$, (\ref{detbal}) will be fulfilled and the sequence $\{r_i\}$ will sample $P$. 
%This rule preserves the relative provability of the transitions between $r_A$ and $r_B$, and preserves the 
%density of walkers in each point.  
Note that only the relative ratio between the left and the right hand side of (eq) are 
of interest to us. Therefore, $P$ does not have to be normalized. 
These equations are implemented in the well known Metropolis-Hastings algorithm as follows:
%
%\begin{algorithm}[h]
\begin{algorithmic}
\LOOP{}
\STATE{$\ts r_B\gets$ random from distribution $g(\ts r_T|\ts r_B)$.}
\STATE{$\mathcal X\gets$ random uniform. ($\mathcal X\in(0,1)$)}%??(0,1)}
\STATE{Calculate $\gamma (\ts r_n|\ts r_T))$.}
\IF{$\mathcal X \le \gamma$}
\STATE{$\ts r_{n+1}\gets \ts r_T$}
\ELSE
\STATE{$\ts r_{n+1}\gets \ts r_n$}
\ENDIF{}
\STATE{$n\gets n+1$}
\ENDLOOP{}
\end{algorithmic}
%\label{alg1}
%\caption{\it The Metropolis-Hastings algorithm. $g(\vec r_T|\vec r_B)$ is the Markov transition kernel and 
%$\gamma (\vec r_n|\vec r_T))$ is the acceptance probability as explained in the text.}
%\end{algorithm}
%
%This algorithm is a 
%Write some more about the algo..
%Alternative algos, and their efficiency. refs.
%(more about the algo: convergence and thermalization (implementation issues))

%}}}2

\subsection{Choice of transition kernel} %{{{2

%The transition kernel can be written as
%\begin{align}
%	q(\ts r_n|\ts r_{n+1}) = \gamma(\ts r_n|\ts r_{n+1}) g(\ts r_n|\ts r_{n+1}), 
%\end{align}
%where $\gamma(\ts r_{n}|\ts r_{n+1})$ is given by eq. (\ref{gamma}). 
%The set $\{r_n\}$ will converge tovards the same distribution $P_w$ regardless of which $g(\ts r_n|\ts r_{n+1})$ we use. 
%(As long as the markov chain defined by $g(\ts r_n|\ts r_{n+1})$ and $\gamma(\ts r_n|\ts r_{n+1})$ is ergodetic.)
%However, the rate of convergence can .. from one sugg.dens. to an other.
%But the rate of convergence can differ widely.
%
%Sampling using a symmetric suggestion density is often referred to as brute force sampling.
%The transition kernel suggested by Markov ... in his original article ...
One possibility us to use a suggestion density $g(\ts r_n|\ts r_{n+1})$ that is symmetric around $\ts r_n$ along all axis. 
This method is referred to as brute force sampling.
In this case $\gamma(\ts r_{n+1}|\ts r_{n})$ can be expressed as
\begin{align} 
	\gamma(\ts r_{n+1}|\vec r_n)=min\left(
	\frac
	{P_w(\ts r_{n+1})}
    {P_w(\ts r_n)}\, 
	,\, 1 \right) \label{gamma_bruteforce}
\end{align}
A common choice is to set
\begin{align}
	g(\ts r_n|\ts r_{n+1}) = l\left(\mathcal U(\ts r_{n+1}-\ts r_n) - \frac12\right)
	\label{sugdebf}
\end{align}
where $l$ is a constant which we will refer to as the step length, and $\mathcal U(\ts r)$ is the uniform distribution
\begin{equation}
	\mathcal U(\ts r) = \left\{ 
	\begin{split} 
		&1, \text{ if all } \ts r \cdot \ts e_i \in [0,1]\\
		&0, \text{ otherwise }\\
	\end{split}
	\right..
\end{equation} 
Here $\ts e_i$ is the unit vectors of $\mathcal D$. 
The step length $l$ will alter the number of 
accepted steps during a simulation, and will have an effect on the rate of convergence. %For example, if nearly all steps are accepted, 

%An other class of sampling algorithms is based on Langevin dynamics describing the dynamical properties of brownian particles obeying the Fokker-Planck equation
%

An other class of transition kernels makes use of our knowledge of the mathematical form of $P$ by using a suggestion density that is dependent on it. 
By solving the Fokker-Planck equation for the stationary distribution $P$ one can construct a transition kernel that in principle will sample $P$ perfectly without the 
Metropolis-Hastings accept/reject procedure \cite{lars_eivind_thesis, scemama_2006}. However, it is necessary to discretize the 
dynamical equations in time $t\to t_n= \Delta t n$, and an time step error arises leading to an imperfect sampling of $P$. %The time step error is quadratic in $\Delta t$ and leads to an imperfect sampling of $P$.
The Metropolis-Hastings algorithm corrects this error %for any time step $\Delta t>0$ 
by restoring detailed balance.% \cite{scemama}.

The suggestion density becomes \cite{lars_eivind_thesis}
\begin{align}
	g(\ts r_{n+1}|\ts r_n)=K\exp(-D\Delta t \frac{\nabla P(\ts r_n)}{P(\ts r_n)} + \ts r_{n+1}-\ts r_{n})^2,	
	\label{sugdeis}
\end{align}
where $D$ is the diffusion constant originating from the Fokker-Planck equation and $K$ is a normalization constant. 
Samples from this density are generated using the Langevin equation on the form (ref HAMMOND) (exact ? or is this where the dt dependent error enters)
\begin{align}
	\ts r_{n+1}=\ts r_n+D\Delta t \frac{\nabla P(\ts r_n)}{P(\ts r_n)} + \sqrt{\Delta t}\mathcal N(\ts r_{n+1}-\ts r_{n}),	
	\label{rp1}
\end{align}
where $\mathcal N$ is a normal distribution with the variance $2D$.
From this equation it is evident that a small $\Delta t$ will lead to a small average step length $|\ts r_{n+1}-\ts r_n|$. This might slow down the 
convergence of the system even though the acceptance rate will increase. %(Since the random walkers in $\mathcal D$ will be very slow + high correlation between samples). 
In practice one has to experiment to find the optimal values for $\Delta t$ that gives a ((small time step error)) and a rapid convergence. 

%}}}

%}}}1

\section{Statistical analysis of the data}%{{{1

The statistical error is defined as the standard deviation of a sample mean, and can be estimated using the formula \cite{m.h-j}
\begin{align}
		err\approx\sqrt{\frac1{N}Var(\mathcal M)},
\end{align}
where $\mathcal M$ is a set of $N$ uncorrelated sample means.  

The samples obtained in the MCMC simulations is heavily correlated, mainly because of the high correlation between succeeding configurations $\ts R$.
%We define the correlation length $\tau$ as the number of steps before the correlation between two configurations is practically zero.
We get an estimate of $err$ by dividing our data into $N_\tau=N/\tau$ bins of $\tau$ samples, and calculating the standard deviation of the $N_\tau$ mean values. 
\begin{align}
	err(\tau)\approx\sqrt{\frac\tau{N_\tau}Var(\mathcal M_\tau)} = \sqrt{\frac{\tau}{N_\tau}\expec{\mathcal M_\tau^2}-\expec{\mathcal M_\tau}^2}.
\end{align}
This is a good estimate if 1) $\tau$ is large enough so that the means $\mathcal M_\tau$ are practically uncorrelated and 2) $N_\tau$ is large enough 
to give us a good statistical value. Starting with a small $\tau$, $err(\tau)$ will converge towards the correct statistical error as $\tau$ increases. 
This method is referred to as blocking analysis. Fig. (\ref{figblc}) shows a plot of $err(\tau)$ for a simulation of a $6$ particle quantum dot with an error
close to $\pm10^{-5}$ Hartrees. The time between two practically uncorrelated samples, when the curve $err(\tau)$ flattens, will be referred to as the correlation length.

\begin{figure}[h!]
\begin{center}
\caption{{\it%\small
		Blocking results for a $6$ particle quantum dot with $\omega=1$ and $\Delta t = 0.05$. A total of $10^8$ samples has been used in the simulation. From the plot we can see that
		the statistical error is close to $\pm10^{-5}$ Hartrees, and that the correlation length is of the order $\mathcal O(10^3)$.}} 
		\label{fig:timesteperror}
%\vspace{-.8cm}
	\includegraphics[width=8.cm]{../plots/blc_6pt_omg1_dt05.eps}
\end{center}
%\vspace{-1.2cm}
\end{figure}

%}}}1

\section{Quantum monte Carlo}%{{{1 

\subsection{Introduction}%{{{2

%In the Heisenberg image, t
The expectation values of an observable $\hat O$ can be expressed on the general form
\begin{align}
	\expec{ O } = \int d\ts r \Psi(\ts r) \hat O \Psi(\ts r)^*,\label{exv}
\end{align}
where $\Psi(\ts r)$ %= \sum_i \psi_i(\ts r)$, for some basis $\{ \psi_i \}$. 
is a solution to the schrÃ¶dinger equation. 
The integral can also be written 
\begin{align}
	\expec{ O } = \int |\Psi(\ts r)|^2 \frac{ \hat O \Psi(\ts r)^\dagger } {\Psi(\ts r)^\dagger},
\end{align}
Since $|\Psi(\ts r)|^2$ is a probability density distribution we see that
\begin{align}
	\expec{ O } \approx \sum_{i=1}^N \frac{ \hat O \Psi(\ts r_i)^\dagger } {\Psi(\ts r_i)^\dagger}, \label{RFQMC1} 
\end{align}
%
where the set of numbers $\{\ts r_i\}$ are drawn from $|\Psi|^2$.
This sum can be sampled using the Metropolis-Hastings algorithm with the acceptance probability 
\begin{align}
	\gamma(r_i|r_i+1)=\frac
		{g(r_i|r_{i+1})\Psi(\ts r_i)|^2}
		{g(r_{i+1}|r_i)|\Psi(\ts r_{i+1})|^2}.
\end{align} 
$g(r_i|r_{i+1})$ is the suggestion density as described earlier.
%
Note that $\Psi$ does not need to be normalized in the above equations. This saves us a great deal of work since the normalization 
of most wave functions would have to be done numerically for every new trial function.% ????
%}}}2

\subsection{Transition kernels}%{{{2
Brute force sampling is implemented using the suggestion density eq. (\ref{sugdebf}) and a acceptance probability
\begin{align} 
	\gamma(\ts R_{n+1}|\ts R_n)=max\left(
	\frac
	{|\Psi(\ts R_{n+1})|^2}
    {|\Psi(\ts R_n)|^2}\, 
	,\, 1 \right) 
\end{align}
%The brute force method is only used during the implementation phase to test the
 
Importance sampling based on Langevin dynamics is implemented using the following equations.
The gradient of $P\to\abs{\Psi}^2$ is
\begin{align}
	\ts F_n=\frac{\nabla|\Psi(\ts R_n)|^2}{|\Psi(\ts R_n)|^2} = 2 \frac{\nabla \Psi(\ts R_n)}{\Psi(\ts R_n)},
\end{align}
and the diffusion constant $D$ can be shown to be $1/2$ in our dimensionless units(ref). Combining these two quantities with eq. (\ref{rp1}) gives 
us an equation to sample the suggestion density eq. (\ref{sugdeis}). 
%
%A new position $\ts R_{n+1}$ is suggested using the equation
\begin{align}
	\ts R_{n+1}&=\ts R_n+\Delta t \frac{\nabla \Psi(\ts R_{n})}{\Psi (\ts R_n)}\notag\\& + \sqrt{\Delta t}\mathcal N(\ts R_{n+1}-\ts R_{n}).
\end{align}
The acceptance probability is found combining eq. (\ref{sugdeis}) and eq. (\ref{gamma}) 
\begin{align} 
	&\gamma(\ts R_{n+1}|\ts R_n)=
	min\left(
	G(\ts R_{n+1},\ts R_n)\frac
	{|\Psi(\ts R_{n+1})|^2}
    {|\Psi(\ts R_{n})|^2}\, 
	,\, 1 \right)
\end{align}
where $G(\ts R_{n+1},\ts R)$ is the greens function
\begin{align}
	G(\ts R_{n+1},\ts R_n)& =%\notag\\&
	 e^{
		-\frac12 
		\Big(\ts F_{n+1}+\ts F_n\Big) }\times\notag\\
	&e^{ 
		\Big(\frac14\Delta t \big(\ts F_{n}-\ts F_{n+1}\big) 
		+ \ts R_{n}-\ts R_{n+1}\Big)}.
\end{align}

%}}}2

\subsection{Variational Monte Carlo}%{{{2

%Variational Monte Carlo (VMC) is used to calculate the lowest energy state $\epsilon_0$ in a quantum mechanical system.
According to the ritz principle, the expectationvalue for the energy 
\begin{align}
	\epsilon_0\ge\bra{\Psi_T} \hat H \ket{\Psi_T}\,\forall\,\ket{\Psi_T}\in\mathcal H.
\end{align} 
%And if $\bra\Psi\hat H \ket\Psi = \epsilon_0$ then $\ket\Psi=\ket{\phi_0}$ where $\ket{\phi_0}$ is the ground state of the hamiltonian. 
%
This means that any expectation value $\expec{\hat H}$ sets an upper limit to the energy of the system. 
%
This principle allows us to perform a systematic search for the lowest $\expec{\hat H}$ using a set of trial wave functions 
$\ket{\Psi_T(\alpha,\beta,\dots)}$ where $\alpha,\beta,\dots$ are variational parameters. % that changes the shape of the wave functions.

The search in the parameter space $(\alpha,\beta, \dots)$ can be done by performing a number of MCMC calculations on a grid. 
More sophisticated methods are also in use, like the stochastic gradient approximation which will be described later in this text.

Since the variance $\expec{\hat H^2}-\expec{\hat H}^2=0$ for the eigenfunctions of $\hat H$, the variance is a measure of how close 
$\ket{\Psi_T,\alpha,\beta,\dots}$ is to the 'true' ground state wave function of the system. Even if the lowest energy obtained in our simulations will be closest 
to the ground state energy, the trial function with the lowest variance might be a better fit to the 'true' ground state wave function. 
%It can be shown (ref) that the minima in energy and variance only concedes for the exact ground state wave function.
%}}}2

\subsection{The trial wave functions}%{{{2

Our system is a closed shell model with the hamiltonian 
\begin{align} 
	\hat H = -\frac{\nabla ^2}2 + \omega |\ts R|^2 - \sum_{i<j}\frac1{r_{ij}}.\label{hamiltonian}
\end{align}
Here $\ts R=(\ts r_1,\ts r_2, \ts r_2, \dots, \ts r_N)$ is a vector containing the position of all electrons in the system.
, and $r_{ij}=|\ts r_i-\ts r_j|$ is the distance between electron $i$ and electron $j$.
The equations
\begin{align}
	\phi_{n_xn_y}^\alpha(\ts r_i) = H_{n_y}(\sqrt{\omega\alpha}y)H_{n_x}(\sqrt{\omega\alpha}x)\notag\\
	\times \exp(-\frac12\omega\alpha|\ts r_i|^2) \label{1pts}
\end{align}
are the eigenstates for the hamiltonian eq. (\ref{hamiltonian}) when $\alpha=1$. $H_n(x)$ is the Hermite polynomials and $\alpha$ is a variational 
parameter $\alpha\in[0,1)$ which represents the ''shielding'' effect that occurs when more than one electron is present in the system. Since the 
electrons carry a negative charge, the efficient external potential seen by the individual particles will be lower than the actual external potential.
%The energy level $n=n_x+n_y$ will be $n+1$ times degenerated. ...

Our trial wave function can be written on the form
\begin{align}
	\Psi(\ts R) = \mathcal D_\downarrow^{\alpha}(\ts R) \mathcal D_\uparrow^\alpha(\ts R) \mathcal J^\beta(\ts R) 
\end{align}
Here $\mathcal D_\uparrow(\ts R)$is a slater determinant consisting of the one particle solutions eq. (\ref{1pts}). Table \ref{tab:orb} shows which orbitals that
enters the slater determinant up to the $6$'th full shell.
The slater determinant automatically fulfills the Pauli principle stating that any wave function consisting of identical fermions must be 
antisymmetric w.r.t. the exchange of two particles.
$\mathcal D_\downarrow^\alpha(\ts R)$ is the corresponding determinant for the spin down states. Note that in the case of a spin dependent hamiltonian,
$\mathcal D^\alpha_\downarrow \mathcal D^\alpha_\uparrow$ would have to be written as one single slater determinant to preserve the antisymmetry of the wavefunction.
This is also the case for the open shell quantum dots since they can have a non zero net spin.
$\mathcal J^\beta(\ts R)$ is the Jastrow factor which removes the singularities in $\hat H \Psi(\ts R)$ at $\ts r_i = \ts r_j$ (ref).
We use a Jastrow factor with one variational parameter $\beta$,
\begin{align}
	&\mathcal J^\beta(\ts R) = \prod_{i<j} \mathcal J_{ij}\notag\\
	&\mathcal J_{ij} = \exp\left( \frac {a_{ij}r_{ij}}{1+\beta r_{ij}} \right)
\end{align}
$a_{ij}=1$ if the spins of particle $i$ and $j$ are parallel and $a_{ij}=\frac13$ if the spins are perpendicular.
See ref. \cite{lars_eivind_thesis} for a detailed derivation of the Jastrow factor.

The wave functions $\psi^\alpha{n_x,n_y}(\ts R)$ is $n+1$ times degenerated in the $n$'th energy level (starting at $0$). 
In the $s$'th full shell we then have $2\sum_{a=1}^s a$ particles. The basis states used in the different energy levels are listed in table (\ref{tab0}).

According to an article written by Tauts (ref tauts), the energy of the $2$ particle $\omega=1$ quantum dot should be exactly $3$ Hartrees.
The kinetic energy ($\hat H\to -\nabla^2/2$) of the slater matrices can be shown to be (ref,appendix): $2\omega$ Hartrees fo two particles, $10\omega$ 
Hartrees for 6 particles, $28\omega$ Hartrees for 12 particles and $60$ Hartrees for 20 particles. (formula)?. We have used this values to verify parts of the code. 

\begin{table}
\begin{center}
\begin{tabular}{|c|c|c|}
\hline
Shell& Electrons & One particle orbitals \\
\hline
1&2& $\psi_{00}$ \\
%\hline
2&6& $\psi_{10},\,\psi_{01}$\\
%\hline
3&12& $\psi_{20},\,\psi_{11},\,\psi_{02}$\\
%\hline
4&20& $\psi_{30},\,\psi_{21},\,\psi_{12},\,\psi_{03}$\\
%\hline
5&30& $\psi_{40},\,\psi_{31},\,\psi_{22},\,\psi_{13},\,\psi_{04}$\\
6&42& $\psi_{50},\,\psi_{41},\,\psi_{32},\,\psi_{23},\,\psi_{14},\,\psi_{05}$\\
\hline
\end{tabular}
\caption{\it 
	This table shows the one particle orbitals that is part of the slater determinants. Only the first orbital state $\psi_{00}$ 
	is needed to fill the first shell. This corresponds to a two electron quantum dot, one spin up and one spin down electron. The
	three first orbitals (six electrons) $\psi_{20},\,\psi_{11},\,\psi_{02}$ are needed to fill the second shell. Six orbitals (twelwe electrons) are needed to fill the third shell and so on.
	%For a quantum dot in the first shell, only $\psi_{00}$ is used, while in the $6$'th shell, all of the orbitals listed above are part of the slater determinants.
\label{tab:orb}
}
\label{tab0}
\end{center}
\end{table}



%}}}2


%}}}1

\section{Minimization of the wave functions}%{{{1

The minimization was performed using the stocastic gradient approach (SGA) \cite{harju_1997,harju_2005,nissenbaum_2008}. 
This is a stocastic procedure which minimizes the gradient of the energy using a large number of sampling points.
%Advantage: shakes its way out of fake/local minima
The variational parameters are updated iteratively using the formula
\begin{align}
	(\alpha_{n+1},\beta_{n+1})=	(\alpha_{n},\beta_{n}) -
	&\gamma_n\left({\partial_\alpha},{\partial_\beta}\right) \expec{E_L}\label{eq:sga1}
\end{align}
The variable steplength $\gamma_n$ is a system dependent parameter that must fulfill
\begin{align}
&	\sum_{n=0}^\infty \gamma_n^2 <
	\sum_{n=0}^\infty \gamma_n = \infty,\notag\\
    &\gamma_n>0,\quad
	lim_{n\to\infty}\gamma_n\to0.\label{eq:sga2}
\end{align}
%When $\gamma_n$ gets smaller the parameters $(\alpha_n,\beta_n)$ will oscillate around the minima with an ever decreasing amplitude. 
%After an initial thermalization phase the average values of $\alpha$ and $\beta$ are collected. 

The SGA is based on the Robbins-Monroe theorem which states that under certain mathematical conditions $\lim_{n\to\infty}(\alpha_n,\beta_n)$ (\ref{eq:sga1})
are guaranteed to converge towards the minima $(\alpha_{min},\beta_{min})$. The mathematical conditions include (\ref{eq:sga2}) and some constraints on the
objective function which is typically met by QMC wavefunctions.
The basis for the theory is discussed in \cite{nissenbaum_2008} with references to the original articles. 

%Choosing the right $\gamma_n$ for the specific system of interest is vital for the rate of convergence of the algorithm.
%$\gamma_n$ is system dependent, so one should devise an algorithm that automatically finds a good value for $\gamma_n$.
%With a $\gamma_n$ that decreases slowly, the fluctuations around the minima will be large, and the convergence might be very slow. 
%With a too large $\gamma_n$ the simulations might spend a long time to reach the minima. 
%The problem is that each physical system has an different optimal value for $\gamma_n$.
%Several approaches hes been used to deal with this problem in the literature.
I have used a $\gamma_n$ on the form
\begin{align}
	\gamma_n=(k * n + l )^{-0.8},
\end{align}
where $k$ and $l$ are parameters that is calculated as a function of the average values of $|\partial_\alpha\expec{E_L}|$ and $|\partial_\beta\expec{E_L}|$ during the first iterations.
$l$ is initially chosen to be $0$, and $k$ to be $1$.
There is one counter $n$ for each of the parameters $\alpha,\beta$ which is updated every time the gradient changes its sign. The reason for this is that it 
is assumed that whenever the gradient changes its sign, the system is close to it's minima\cite{harju_2005}. 

The maximum step length is set to $0.1$. This stabilizes the simulation during the initial phase when $\gamma_n$ is small and the step length might be large.
After the thermalization phase $\gamma_n$ is chosen so that the average step length becomes much smaller than $0.1$.
%The first $30$ iterations is thermalization cycles. During the next $40$ iterations the averages of $|\partial_\alpha\expec{E_L}|$ and $|\partial_\beta\expec{E_L}|$ is collected. 
%After $70$ iterations, $l$ is chosen so that the average step length in each direction divided by $l$ is equal to $1/300$, $k$ is chosen to be $l/20$ and
%$n$ is reset to $0$.
%After $k$ and $l$ are set the averages of the variational parameters are collected. 
%\end{itemize}

The approximate value of the gradient $\left({\partial_\alpha},{\partial_\beta}\right)\expec{E_L}$ is obtained during a short MC run where $m=\mathcal O (10)$ uncorrelated samples are 
collected. I have used $m$ different walkers that collect one sample each every iteration. 
I also tried to use one walker collecting $m$ samples every iteration, but % because of the high correlation between the samples, it was 
%necessary to use a high number of samples $\matcal O(10^3)$ for the simulation to give the correct results. 
the high correlation between the samples leads to bad results if the number of samples $m$ is much smaller than the correlation length ($\mathcal O(10^3)$). 
%(close to the correlation length found during the blocking analysis), while $\mathcal O(10)$ is enough when $m$ walkers are used. 
After my experience, using many uncorrelated walkers instead of one speeds up the convergence of the algorithm considerably. %since the total number of samples decreases.

See algorithm \ref{minalg} for a detailed pseudo code.

The algorithm proved efficient when applied on the full shell quantum dots.%, generally converging to results with an error close to $(10^{-3})$ in less than $10^6$.total MC samples.
The optimization of the two particle quantum dots is done in a few seconds, the six particle quantum dot in less than thirty seconds and the twelve particle QD in about four minutes.
All with an statistical error close to $10^{-3}$.

Note that the optimization converges much faster than one can calculate the energy. For example, to optimize the two particle quantum dot with an error in the variational parameters 
$\sim10^{-3}$, only a few hundred thousand samples is needed (see figure ?), with a minima that is accurate to $\mathcal O (10^{-5})$ Hartrees. 
To obtain the energy with an error $\sim 10^{-5}$ Hartrees about $10^8$ MC-samples are needed.

\begin{figure}[h!]
\begin{center}
\caption{{\it%\small 
	Minimization of a $6$ particle (top) and a $12$ particle (bottom) quantum dot using an $\omega = 1$ and a $\delta t=0.05$. $N_C$ is the total number of MC-samples. 
	The red line shows the $\alpha$ and $\beta$ values at $N_C$, while the black line shows the accumulated mean.
	The means are quickly converging towards the optimal results ($\beta=0.399$, $\alpha=0.988$) (top) and ($\beta=0.877$, $\alpha=0.657$) (bottom), 
	only using a total of total of $6\times10^5$ samples. }}
\vspace{-.3cm}
	\includegraphics[width=7.8cm]{../plots/minimization_2pt_omg1.eps}
%\end{center}
%\end{figure}
%\begin{figure}[h]
%\begin{center}
	\includegraphics[width=7.8cm]{../plots/minimization_12pt_omg1.eps}
\end{center}
\vspace{-.8cm}
\end{figure}



%We first tried to use the minimization algorithm we use is the Broyden-Fletcher-Goldfarb-Shannon (BFGS) method. The algorithm itself is copied from (ref numerical recipes), and is a 
%so called Quasi-Newton method which iteratively updates the inverse hessian matric $A^{-1}$, which has the property.
%\begin{align}
%	(\alpha_{min},\beta_{min})= (\alpha_{0},\beta_{0}) - A^{-1}\cdot \nabla \Psi(\ts R,\alpha,\beta)\big|_{(\alpha_{0},\beta_{0})}
%\end{align}
%The function recieves pointers to a sampling method which returns the energy $\expec {\hat E_L}$ and the gradient of the energy in the point $(\alpha,\beta)$, and updates the
%inverse hessian every time new values are returned. The function also recieves a variable \verb gtol  which sets the limit of convergence for the algorithm. If \verb gtol  $=0$ 
%the function will continue iterating till it has localized the point where the gradient is zero. 

%The algorithm performs badly if {\verb gtol } is to high or if the number of cycles used to find the energy is to low. On the other hand, minimizing the function
%with a high accuracy can be very time consuming. I found that a good strategy is to use %a large {\verb gtol } in the range $\mathcal O(10^{-4})-\mathcal O(10^{-5})$ with
%a lesser number of sampling cycles $\mathcal O (10^4)-\mathcal O(10^5)$ to get an estimate to the optimal values for $\alpha,\,\beta$. Then I use a %small {\verb gtol }
%%$\mathcal O(10^{-8})$ and a 
%larger number of sampling cycles $\mathcal O (10^6)-\mathcal O (10^7)$ to find a better approximation. 
%
%The BFGS algorithm is a deterministic approach designed to work well when applied on a deterministic system. For a stocastic system like ours, the algorithm was very inefficient.
%To obtain the minima in $(\alpha,\beta)$ with 3 significant digits, I used $10^7$ sampling cycles to sample each point $(\alpha_i,\beta_i)$. Even with a good starting point, the total number of
%samples needed to find a minima exceeded $10^8$, often giving bad results because of false minima induced by statistical fluctuations. 
%
%starting vals alpha,beta .5,.5
%

%
%
%
%The minimas are very good. 
%To distinguish the energy between minimas that is as close as $10^{-3}$ in $(\alpha,\beta)$, more than $\mathcal O 10^8$ 
%cycles are needed. ...
%
%  To obtain   energies was calculated using $\mathcal O 10^8$ cycles  b0.399/0.401, a0.988/.99, E3.00038/3.00040, error $\sim 10^{-5}$
%
%
%Comparisons with the literature:
%Nissenbaum has implemented a different SGA algirithm in \cite{nissenbaum_2008}. Here a line search is performed each step. This means that it is unneccesary to tune $\gamma_n$
%for each new system. An other advantage is that the algorithm is much more efficient for asymmetric objective functions ... 
%One way of performing the line search would be to calculate the hessian matrix and
%For example, in \cite{nissenbaum_2008} a line search is performed along the direction of the gradient to find the minima during each iteration. 
%One possibility is to calculate the hessian matrix and to use the Newton method. 
%It is reported that this approach speeds up the convergence considerably. 
%Mainly for unsymmetrical minima, because of the difference in the magnitude of the
%gradient in the neighbourhood of the minima. steep side: shoots out to flat side, long way back..
%


%COMPARISONS:
%Example: %(d/da = (f(a+h)-f(a+h))/2h),h=0.001. For example, for $\omega = 0.28,\, \Delta t=0.05$ with $6$ electrons, I got the results $\alpha=0.87269,\beta=0.32655$ giving an
%energy $E=7.6214(1)$ and a variance ... . $(?).6218(1)$ .
%}}}1

\section{Implementation and optimization}%{{{1

The simulator can be efficiently optimized by implementing some mathematical shortcuts. The optimalizations can only be done if we only change the position of one electron at the time.
The metropolis-hastings test is performed each cycle, while the energy and other observables are updated when we have cycled through all electrons. It would also be possible to
evaluate the energy every time a electron has been moved, but this would not be favorable for a system with many electrons since the correlation between the samples would be very high, 
and the evaluation of the energy consumes too many flops. 

\subsection{Random number generators}
I have used the random number generator \verb DRanNormalZig32  for generating normal distributed random numbers and \verb DRan_MWC8222  for generating uniformly distributes random numbers. 
The random number generators are programmed by Jurgen A. Doornik \cite{Doornik}. 

\subsection{The update algorithm}%{{{2
%}}}2

\subsection{Optimalization of $\mathcal D^\alpha(\ts R)$} %{{{2

The inverse $D^{-1}$ of a matric $D$ can be written as the cofactor matrix $C/|D|$. $C$ has the elements $C_{ij}=|S_{ij}|$ where $S_{ij}$ is a sub matrix of $D$ with the $i$'th row and the 
$j$'th coloumn removed. The determinant $|D|$ can be expressed as 
\begin{align}
	&1=\sum_j D_{ij}D^{-1}_{ji}=\sum_jD_{ij}\frac{C_{ji}}{|D|}\notag\\
	&\Rightarrow \sum_jD_{ij}C_{ji}=|D|
\end{align}
From the definition of $C_{ij}$, we see that the $i$'th coloumn of $D^{-1}=C/|D|$ is unchanged if we change the $i$'th row of $D$.
Therefore,
\begin{align}
	&\text{if } D'_{ij}=D_{ij} \forall i\neq k\notag\\
	&\sum_k D'_{kj} D'^{-1}_{jk} = \sum_k D'_{kj} D^{-1}_{jk} = \sum_k D'_{kj} \frac{C^{-1}_{jk}}{|D|}\notag\\ 
	&\Rightarrow \sum_k D'_{kj} D'^{-1}_{jk} = \frac{|D'|}{|D|}\label{eqDet}
\end{align}
This operation scales much better than alternative ways of evaluation the determinant. For example ... 
The problem is that we need to obtain an expression for the inverse matrix $D^{-1}$. By using ... (ref) formula for updating the inverse
matrix, we only need to evaluate the inverse matrix once. Updating the matrix scales as ...

Eq. (\ref{eqDet}) can be used to calculate the ratios
\begin{align}
	&\frac{\mathcal D^\alpha(\ts R')}{D^\alpha(\ts R)}=\sum_{ij} (\mathcal D_{ij})\mathcal D^{-1}_{ji}\\
	&\frac{\nabla^2\mathcal D^\alpha(\ts R)}{D^\alpha(\ts R)}=\sum_{ij} (\partial^2_{r_i}\mathcal D_{ij})\mathcal D^{-1}_{ji}\\
	&\frac{\nabla_i\mathcal D^\alpha(\ts R)}{D^\alpha(\ts R)}=\sum_{j} (\partial_{r_i}\mathcal D_{ij})\mathcal D^{-1}_{ji}
\end{align}
since all expressions can be written as a sum of slater determinants where only one row is changed. 
$\ts R'$ is equal to $\ts R$ except for the coordinates of one electron.
The expressions for $\partial_{r_i}\mathcal D_{ij}$ and
$\partial^2_{r_i}\mathcal D_{ij}$ is calculated by evaluating the analytical expressions 
\begin{align}
	\partial^2_{r_i}\mathcal D_{ij} &= % \partial^2_{r_i}=\notag\\
	\psi_{n_{xi},n_{yi}}((x_j,y_j),\alpha) \, \omega\alpha\notag\\
	&\bigg( 
		\frac{\omega}2(x_j^2+y_j^2)-2\notag\\
	&	+4n_{xi}(n_{xi}-1) \frac{H_{n_{xi}-2}(\sqrt{\omega\alpha}x_j)}{H_{n_{xi}}(\sqrt{\omega\alpha}x_j)}\notag\\
	&	+4n_{yi}(n_{yi}-1) \frac{H_{n_{yi}-2}(\sqrt{\omega\alpha}y_j)}{H_{n_{yi}}(\sqrt{\omega\alpha}y_j)}\notag\\
	&		-4x\sqrt{\omega\alpha}\,n_{xi}\frac{H_{n_{xi}-1}(\sqrt{\omega\alpha}x_j)}{H_{n_{xi}}(\sqrt{\omega\alpha}x_j)}\notag\\
	&		-4y\sqrt{\omega\alpha}\,n_{yi}\frac{H_{n_{yi}-1}(\sqrt{\omega\alpha}y_j)}{H_{n_{yi}}(\sqrt{\omega\alpha}y_j)}
	\bigg)\\
 	\partial_{r_i}\mathcal D_{ij} &%= \partial_{r_i}\psi_i(\ts r_j)=\notag\\
	=\psi_{n_{xi},n_{yi}}((x_j,y_j),\alpha) \notag\\
		&\bigg( 
		\ts e_x(2n_{xi}\sqrt{\omega\alpha}\frac{H_{n_{xi}-1}(\sqrt{\omega\alpha}x_j)}{H_{n_{xi}}(\sqrt{\omega\alpha}x_j)}-x\omega\alpha)\notag\\
		&\ts e_y(2n_{yi}\sqrt{\omega\alpha}\frac{H_{n_{yi}-1}(\sqrt{\omega\alpha}y_j)}{H_{n_{yi}}(\sqrt{\omega\alpha}y_j)}-y\omega\alpha)
		\bigg)
\end{align}
The expressions is derived using the same strategy as we have used when $(\partial_\alpha)\psi_i(\ts r_j)$ is derived in appendix A.
The full derivation is found in \cite{lars_eivind_thesis}.
When only one particle is updated, only one of the determinants $\mathcal D_\downarrow$, $\mathcal D_\uparrow$ needs to be evaluated since ...
Analytical vs. numerical derivatives.
%}}}2

\subsection{Optimalization of $\mathcal J^\beta(\ts R)$ and $r_{ij}$}%{{{2
There are only $n(n-1)/2$ distinct values of $r_{ij}$. Therefore, all values can be stored in a lower tridiaginal matric with zeros on the diagonal.
\begin{align}
	P = 
\left(
\begin{matrix}
	0 		& 0	 	&0 		&\dots	&\\
	r_{21}  & 0 	&0 		& &\\
	r_{31} 	& r_{32}&0 		& &\\
	r_{41} 	& r_{42}&r_{43} & &\\
	\vdots 	& 		& 		& &\\
\end{matrix}
\right)\label{eqP}
\end{align}
If we move one electron, only $(n-1)$ elements has to be updated. 

The electron-electron potential can be directly calculated by summing the $(n-1)$ inverse elements of $P$. The Jastrow ratio can be calculated
\begin{align}
	\frac{\mathcal J^\beta(\ts R')}{\mathcal J^\beta(\ts R)}
	= \prod_{i=k\text{ or }j=k} \frac{ \mathcal J_{ij}^\beta(\ts R') }{ \mathcal J_{ij}^\beta(\ts R)}
\end{align} 
when only the electron with coordinates $\ts r_k$ has been moved. This expression can be efficiently evaluated as the exponential of the sum of $2(n-1)$ elements
\begin{align}
	&\frac{\mathcal J^\beta(\ts R')}{\mathcal J^\beta(\ts R)}=
	\exp\left(\sum_{i=k\text{ or }j=k}  j(r_{ij})  - j(r'_{ij}) \right)\notag\\
	&j(r_{ij})=\frac {a_{ij}r_{ij}}{1+\beta r_{ij}}.
\end{align}
The laplacian and the gradient $..$ can be evaluated ...
the gradient: subltract old value, add new.
%}}}2 

\subsection{Optimalization of $(\partial_\alpha,\partial_\beta)\expec{E_L}$}%{{{2
The gradient are calculated using an analytical expression for the energy. 
%In the cases where comparisons where performed, the analytical expressions gave better results then the numerical derivatives.
%The gradient of the expectationvalue of the energy can be written 
\cite{lin_2000}
\begin{align}
	&\left({\partial_\alpha},{\partial_\beta}\right) \expec{E_L} = \notag\\
		&2\Big\langle\frac{\left({\partial_\alpha},{\partial_\beta}\right)\Psi}{\Psi} E_L\Big\rangle
		-2\Big\langle\frac{\left({\partial_\alpha},{\partial_\beta}\right)\Psi}{\Psi}\Big\rangle\expec{E_L}\label{abgd},
\end{align}
%To find the gradients I used the expression
where
\begin{align}
	&\frac{\left({\partial_\alpha},{\partial_\beta}\right) \Psi(\ts R,\alpha,\beta)}{\Psi(\ts R,\alpha,\beta)}\notag\\
	&= 	\left(\frac{\partial_\alpha \mathcal D(\ts R,\alpha)}{\mathcal D(\ts R,\alpha)}
	, 	\frac{{\partial_\beta} \mathcal J(\ts R,\beta)}{\mathcal J(\ts R,\beta)}\right)
\end{align}
From the definition of the Jastrow eq. (..) we can derive
\begin{align}
	\frac{\partial_\beta \mathcal J(\ts R,\beta)}{ \mathcal J(\ts R,\beta)}=\sum_{k<l}-a
\left( 
	\frac {r_{kl}} {1+\beta r_{kl}}.
\right)^2
\end{align}
The expression is calculated as a sum over the relevant distances $r_{kl}=|\ts r_k-\ts t_l|$ which is already stored in the matrix $P$ (\ref{eqP}).
The gradient of alpha is calculated using the expression:
\begin{align}
	&\frac{\partial_\alpha \mathcal D(\ts R,\alpha)}{\mathcal D(\ts R,\alpha)}=\sum_i\sum_j(\partial_\alpha \psi_i(\ts r_j,\alpha)) \mathcal D^{-1}_{ji} %INDEXES OK??
\end{align}
\begin{align}
	&\partial_\alpha \psi_i(\ts r_j,\alpha)=\notag\\
	&\psi_{n_{xi},n_{yi}}((x_j,y_j),\alpha)
	\bigg(
	 	n_{xi} \sqrt{\frac\omega\alpha} \frac{H_{n_{xi}-1}(\sqrt{\omega\alpha}x_j)}{H_{n_{xi}}(\sqrt{\omega\alpha}x_j)}\notag\\
	 	&+n_{yi} \sqrt{\frac\omega\alpha} \frac{H_{n_{yi}-1}(\sqrt{\omega\alpha}y_j)}{H_{n_{yi}}(\sqrt{\omega\alpha}y_j)}
		-\frac{\omega}2(x_j^2+y_j^2)
	\bigg)
\end{align}
Here $r_j\to(x_j,y_j)$ and $i\to n_{xi},n_{yi}$.  
The values 	$\partial_\alpha \psi_i(\ts r_j,\alpha)$ are already stored in the matrix $\mathcal D$, and does not have to be calculated. 
All of the analytical expressions above is derivated in appendix A.
%}}}2


%}}}1

\section{Results} %{{{1

\subsection{Scaling and time consume}%{{{2

I have used the package \verb GNU  \verb gprof  to profile my program. 

The time spent on running the code for $n_p=\{2$, $6$, $12$, $20\}$ particles is listed in table \ref{tab:scaletime}. 
A curve fit to this data indicates that the algorithm scales as $\mathcal O(n_p^{2.5})$. 

In table \ref{tab:scaletime} I have also listed the percentage of the total floating point operation spent on the three most expensive functions. 
%For the $2$ and $6$ particle quantum dots, the evaluation of the gradients was the most time consuming part of the code. 
%For the $6$ and $12$ particle quantum dots 
The evaluation of the first derivatives of the single particle orbitals soon becomes the most time consuming part of the code.
This part of the code scales bad since the mathematical expressions for the orbitals eq. (\ref{1pts}) gets more complex as the orbital energies increases.
% since Hermite polynomials of an higher order must be calculated.
The problem is that half of these derivatives are calculated each time one particle is moved. 
It is possible to store the values, reducing the number of analytical expressions that has to be calculated $n/2$ times (?).
This did not pay off when I tried to implement it since the number of variables that has to be stored is too high ($1/2(n_p)^2$(*dim?) for our system).
The copying and accessing of the elements when accepting or rejecting a move is simply too expensive.
%It does not pay off storing them since the number of derivatives is
%$1/2(n_p)^2$(*dim?) for our system, and half of the derivatives would have to be updated every time a move is accepted and reset every time a move is rejected.

%1) calculating the first derivative of the orbitals, 
%2) calculating the gradients of the slater determinant (the orbital derivatives are not included)
%and 3) calculating the gradient of the jastrow factor are listed.
%The functions calculating the gradient of the jastrow function and the slater determinant consumes less than 15\% of the computational load each for all simulations. 
%The function that updates the inverse slater matrix consumes even less.

\subsection{Systematic errors}

Systematic time step error see HAMMOND (monte carlo methods in ab initio quantum chemistry)

\begin{figure}[h!]
\begin{center}
\caption{{\it%\small
			Energy as a function of $\Delta t$ for a $2$ particle quantum dot with $\alpha=0.988,\beta=0.399,\omega=1$. All energies are calculated using $10^7$ samples.
			The energy are plotted for 40 values of $\Delta t$ between $0.01$ and $0.4$. 
		}}
		\label{fig:ef}
%\vspace{-.8cm}
	\includegraphics[width=8.cm]{../plots/time_step_error_2ptomg1.eps}
\end{center}
%\vspace{-1.2cm}
\end{figure}

\begin{figure}[h!]
\begin{center}
\caption{{\it%\small
			Different quantities are plotted as a function of $\omega$ for a $2$ particle quantum dot with the optimal variational parameters. 
			All energies are calculated using $10^7$ samples and $\Delta t = 0.05$.
			Top plot: The total energy.
			Middle plot:
			Blue line ($-+$): kinetic energy, red line ($-\times$) oscillator potential energy, black line ($-*$) electron-electron potential energy.
			Percentage of total energy for each $\omega$ plotted.
			Bottom plot: The Jastrow energy as a percentage of the total energy. ((Hartree-Fock energy) - $\expec{E_L}$ ) / $\expec{E_L}$. 
		}}
		\label{figes}
%\vspace{-.8cm}
	\includegraphics[width=6.5cm]{../plots/energies2pt.eps}
\end{center}
%\vspace{-1.2cm}
\end{figure}

\begin{figure}[h!]
\begin{center}
\caption{{\it%\small
		The single particle densities for a two particle dot with $\omega=1$ (top plot) and $\omega=0.01$ (bottom plot). 
		The single particle densities are calculated with and without the Jastrow function. These plots demonstrates that the correlation effects 
		included in the Jastrow function are more important when $\omega$ gets small.
		}}
		\label{fig:ef}
\vspace{.1cm}
	\includegraphics[width=7.7cm]{../plots/spds.eps}
\end{center}
%\vspace{-1.2cm}
\end{figure}

\begin{table}[h!]
\begin{center}
\begin{tabular}{|c|c|c|c|c|}
\hline
$N_{p}$ & cpu time & d1  & jasgrad  & slagrad  \\ 
\hline
\hline
 $2$  & $1.1s$ &4\% &10\% &6\%\\ 
 $6$  & $8.5s$ & 10\% &16\% &14\%\\ 
 $12$ & $37.8s$ & 20\% &14\% &13\%\\ 
 $20$ & $135.3s$ & 37\% &11\% &16\%\\ 
\hline
\end{tabular}
\end{center}
\caption{{\it 
	Running time for $\omega=1$ quantum dots with $N_p$ particles and the optimal values for the variational parameters. All runs done on one $2.4 MHz$ processor with $10^6$ iterations.
	The percentage of time consume of the most expensive functions are listed in the table. 
	(d1) :evaluation of the first derivatives of the orbitals,
	(jasgrad)  :evaluation of the gradient of the Jastrow factor,
	(slagrad)  :evaluation of the gradient of the Slater matrix (d1 not included).
}}
\label{tab:scaletime}
%\hspace{50mm}
\end{table}


\subsection{Numerical results}
%{{{2

The results are summarized in tables \ref{tab1} and \ref{tab2}. I have used the values $\omega=0.28,0.5,1.0$ and $\Delta t = 0.01,0.25,0.05$ to be able to compare my 
results with ref(...). I have also calculated the values using the same number of cycles. The results are well consistent with the results of (refLE),..

Speed tests.

%but the minima obtained seems to give lower energies in most cases cases. 
%This can probably be explained by the fact that I have used a analytical expression to calculate $(\partial_\alpha,\partial_\beta) \expec{E_L}$ while
%() has evaluated the gradient numerically. (List his results in table...)   

The timestep error: We have calculated all energy with three different values for $\Delta t$. 
The timestep error seems to be of the same order as the statistical error for our values of $\Delta t$. 
There is also a general trend in the variance and the statistical error as a function of $\Delta t$. The variance and the statistical error increases as $\Delta t$ gets smaller.
The correlation length((plots?)) are generally increasing when $\Delta t$ gets smaller, probably explaining the increase in the variance and statistical error since the system will use a longer
time to equilibriate after random fluctiations away from equilibrium (eg. if a sequence of mc-steps with a very low metropolis probability are accepted).
%
%The variance is systematically larger for low values of omega. This might indicate that our trial function is further away from the 'true' groundstate solution of the hamiltonian.
%For low $\omega$, the 





 can see that the timestep error   a 


\begin{table}[h!]
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|}
\hline
$N_{p}$ & $\omega$ & $N_{s}$ & $\alpha_{min}$ & $\beta_{min}$ \\ 
\hline
\hline
 $2$  & $0.28$ & $10^7$ & $0.971$ & $0.252$ \\ 
 $2$  & $0.5$  & $10^7$ & $0.981$ & $0.309$ \\ 
 $2$  & $1$    & $10^7$ & $0.988$ & $0.399$ \\ 	 
\hline
 $6$  & $0.28$ & $10^7$ & $0.873$ & $0.326$ \\ 
 $6$  & $0.5$  & $10^7$ & $0.900$ & $0.413$ \\ 
 $6$  & $1.0$  & $10^7$ & $0.924$ & $0.557$ \\ 
\hline
 $12$ & $0.28$ & $10^7$ & $0.809$ & $0.378$ \\ 
 $12$ & $0.5$  & $10^7$ & $0.845$ & $0.482$ \\ 
 $12$ & $1.0$  & $10^7$ & $0.877$ & $0.658$ \\ 
\hline
\end{tabular}
\end{center}
\caption{{\it 
	Minimization results. $N_p$ is the number of particles and $N_s$ is the number of cycles used to obtain the energies and the gradient during the minimization.
	$\alpha_{min}$ and $\beta_{min}$ is the values of the variational parameters at the minima. 
	%The variable \verb gtol  which sets the convergence criteria
	We have used a $\Delta t=0.05$ during the minimization. 
}}
\label{tab1}
%\hspace{50mm}
\end{table}

\begin{table}%[h!]
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|}
\hline
$N_{p}$ & $\omega$ & $\Delta t$ & $N_{s}$ & $\expec{E_L}$ & $\sigma^2$ \\ 
\hline
\hline
 $2$ & $0.28$ & $0.01$  & $10^8$ & $1.02213(3)$ & $0.00076627$ \\ 
 $2$ & $0.28$ & $0.025$ & $10^8$ & $1.02219(2)$ & $0.00075989$ \\ 
 $2$ & $0.28$ & $0.05$  & $10^8$ & $1.02218(1)$ & $0.00076032$ \\ 
\hline
 $2$ & $0.5$ & $0.01$  & $10^8$ & $1.66022(3)$ & $0.00116982$ \\ 
 $2$ & $0.5$ & $0.025$ & $10^8$ & $1.66024(2)$ & $0.00116586$ \\ 
 $2$ & $0.5$ & $0.05$  & $10^8$ & $1.66025(1)$ & $0.00116698$ \\ 
\hline
 $2$ & $1.0$ & $0.01$  & $10^8$ & $3.00030(3)$ & $0.00183428$ \\ 
 $2$ & $1.0$ & $0.025$ & $10^8$ & $3.00036(2)$ & $0.00182671$ \\ 
 $2$ & $1.0$ & $0.05$  & $10^8$ & $3.00038(1)$ & $0.00182404$ \\ 
\hline
\hline
 $6$ & $0.28$ & $0.01$  & $10^8$ & $7.6213(1)$ & $0.017831$ \\ 
 $6$ & $0.28$ & $0.025$ & $10^8$ & $7.6214(1)$ & $0.017634$ \\ 
 $6$ & $0.28$ & $0.05$  & $10^8$ & $7.6214(1)$ & $0.017383$ \\ 
\hline
 $6$ & $0.5$ & $0.01$   & $10^8$ & $11.8100(2)$ & $0.043103$ \\ 
 $6$ & $0.5$ & $0.025$  & $10^8$ & $11.8108(1)$ & $0.042331$ \\ 
 $6$ & $0.5$ & $0.05$   & $10^8$ & $11.8101(1)$ & $0.041268$ \\ 
\hline
 $6$ & $1.0$ & $0.01$  & $10^8$ & $20.1898(3)$ & $0.123116$ \\ 
 $6$ & $1.0$ & $0.025$ & $10^8$ & $20.1904(2)$ & $0.119393..$ \\ 
 $6$ & $1.0$ & $0.05$  & $10^8$ & $20.1905(1)$ & $0.115563$ \\ 
\hline
\hline
 $12$ & $0.28$ & $0.01$  & $10^8$ & $25.6994(4)$ & $0.0621312$ \\ 
 $12$ & $0.28$ & $0.025$ & $10^8$ & $25.6993(3)$ & $0.0611159$ \\ 
 $12$ & $0.28$ & $0.05$  & $10^8$ & $25.6993(2)$ & $0.0599358$ \\ 
\hline
 $12$ & $0.5$ & $0.01$  & $10^8$ & $39.2356(4)$ & $0.153526$ \\ 
 $12$ & $0.5$ & $0.025$ & $10^8$ & $39.2345(3)$ & $0.149480$ \\ 
 $12$ & $0.5$ & $0.05$  & $10^8$ & $39.2344(2)$ & $0.145622$ \\ 
\hline
 $12$ & $1.0$ & $0.01$  & $10^8$ & $65.7908(5)$ & $0.441007$ \\ 
 $12$ & $1.0$ & $0.025$ & $10^8$ & $65.7904(3)$ & $0.424902$ \\ 
 $12$ & $1.0$ & $0.05$  & $10^8$ & $65.7903(2)$ & $0.409616$ \\ 
\hline
\end{tabular}
\end{center}
\caption{{\it 
	Monte carlo results using the variational parameters in table (\ref{tab1}).
	Minimization results. $N_p$ is the number of particles and $N_s$ is the number of cycles used to obtain the energies and the gradient during the minimization.
	The thermalization is set to $5\times 10^5$. The error is estimated using blocking analysis of the data. 
%The variable \verb gtol  which sets the convergence criteria
}}
\label{tab2}
%\hspace{50mm}
\end{table}

The SGA algorithm works well. First of all, it seems as the algorithm is working for different systems. Some parameter tuning seems inevitable for any new system. This can be solved by implementing
some sort of line search along the gradient $\partial ...$. One possibility is to implement a Newtonian approach to estimate the minima for each iteration. The hessian matrix can be evaluated 
analytically for each new configuration of the system [ref]. This approach has many advantages. In particular for trial functions with asymmetrical minima, 
where the gradient is larger on one side of the minima then on the other. For an algorithm without an adaptive step size, the step length will have to be very small to give accurate results.


Two reasons: 1) mean value of variational parameters taken gives higher stability.
The algorithm as it is implemented by (refs) Does not take the mean, but lets $\gamma$ increase faster to obtain a 

%}}}1

\begin{appendix}
\section{Pseudocode: The SGA algorithm.}%{{{1
My implementation of the SGA. %All numbers are tunable parameters that can be changed.
At $n=N_A/N_B$ start/stop collecting mean value of gradient. At $n=N_B$, $k,l$ is calculated.
At $N_C$ the system should be thermalized and we start collecting data.
$v_{min}$ is the lower limit of the variational parameters $\alpha,\beta$. $d_{max}$ is the upper limit for the 
length of a step in each variational parameter. $k,l$ are dependent on $D,E,F$. $E$ is the (negative) exponent limited by eq. (\ref{eq:sga2}).
I have used $m=30$, $N_A=50$, $N_B=120$, $N_C=200$, $v_{min}=0.01$, $d_{max}=0.1$, $D=300$, $E=0.8$, $F=20$ in all calculations. 
%\vspace{-.6cm}
%\begin{algorithm}[h!]
\begin{algorithmic}
\STATE{**Initialize $m$ walkers**}
\STATE{$k_\alpha\gets0,l_\alpha\gets1$}
\STATE{$k_\beta\gets0,l_\beta\gets1$}
	\LOOP{}
		\STATE{$n=n+1$}
		\FOR{all walkers }
			\STATE{propose new position for walker}
			\STATE{accept/reject move (metropolis test)}
			\STATE{sample $\left({\partial_\alpha},{\partial_\beta}) E_L ,E_L$, $({\partial_\alpha},{\partial_\beta}) E_L* E_L$}
		\ENDFOR{}
		\STATE{$(\partial_\alpha,\partial_\beta)\expec{E_L}\gets$ use eq. (\ref{abgd})}
		\FOR{$\nu=\{\alpha,\beta\}$}
			\IF{$n\in[N_A,N_B)$}
				\STATE{$\Delta_\nu\gets\Delta_\nu+|\partial_\nu\expec{E_L}|$}
				%\STATE{$\Delta_\beta=\Delta_\beta+|\partial_\beta\expec{E_L}|$}
			\ENDIF{}
			\IF{$n=N_B$}
				\STATE{$l_\nu\gets D^{E} (\Delta_\nu/(N_B-N_A))^{-E} $}
				\STATE{$k_\nu\gets l_\nu/F$}
				\STATE{$n\gets0$}
				%\STATE{$l_\beta=300^{0.8} (\Delta_\beta/40)^{0.8} $}
				%\STATE{$k_\alpha=l_\alpha/20$}
			\ENDIF{}
			\IF{$|\partial_\nu\expec{E_L}|>d_{max}$}
				\STATE{$\nu\gets\nu-d_{max}*\partial_\nu\expec{E_L}/|\partial_\nu\expec{E_L}|$}
			\ELSE{}
				\STATE{$\nu\gets\nu-\partial_\nu\expec{E_L}(k_\nu*n+l_\nu)^{-E}$}
			\ENDIF{}
			%\IF{$\partial_\beta\expec{E_L}>0.1$}
			%	\STATE{$\beta=\beta-0.1$}
			%\ELSE{}
			%	\STATE{$\beta=\beta-\partial_\beta\expec{E_L}(k_\beta*n+l_\beta)^{-0.8}$}
			%\ENDIF{}
			\IF{$\nu< v_{min}$}
				\STATE{$\nu\gets v_{min}$}
			\ENDIF{}
			\IF{$\partial_\nu\expec{E_L}$ has changed its sign}
				\STATE{$n_\nu\gets n_\nu+1$}
			\ENDIF{}
		\ENDFOR{}
		\IF{$n>N_C$}
			\STATE{accumulate mean values of $\alpha,\beta$}
		\ENDIF{}
	\ENDLOOP{}
\end{algorithmic}
%\caption{My implementation of the SGA. %All numbers are tunable parameters that can be changed.
%At $n=N_A/N_B$ start/stop collecting mean value of gradient. At $n=N_B$, $k,l$ is calculated.
%At $N_C$ the system should be thermalized and we start collecting data.
%$v_{min}$ is the lower limit of the variational parameters $\alpha,\beta$. $d_{max}$ is the upper limit for the 
%length of a step in each variational parameter. $k,l$ are dependent on $D,E,F$. $E$ is the (negative) exponent limited by eq. (\ref{eq:sga2}).
%I have used $m=30$, $N_A=50$, $N_B=120$, $N_C=200$, $v_{min}=0.01$, $d_{max}=0.1$, $D=300$, $E=0.8$, $F=20$ in all calculations. 
%}
%\label{minalg}
%\end{algorithm}
%}}}1

\section{Derivation of the analytical expressions for $(\partial_\alpha,\partial_\beta)\expec{\hat H}$}%{{{1

The derivative of the jastrow factor can be written
\begin{align}
	&\partial_\beta \mathcal J(\ts R,\beta) =\partial_\beta \prod_{i<j} \mathcal J_{ij}(\ts R,\beta)\notag\\ 
	&= \sum_{k<l}\partial_\beta \mathcal J_{kl}(\ts R,\beta) 
		\prod_{
		%\begin{matrix}
			i<j,
			(i,j)\neq(k,l) 
		%\end{matrix}
		}
	\mathcal J_{ij}(\ts R,\beta).
\end{align}
We are interested in the ratio
\begin{align}
	\frac{\partial_\beta\mathcal J(\ts R,\beta)}{\mathcal J(\ts R,\beta)}
	=\frac{\partial_\beta \prod_{i<j} \mathcal J_{ij}(\ts R,\beta) }
	{\prod_{i<j} \mathcal J_{ij}(\ts R,\beta)}
	= \sum_{k<l}\frac{\partial_\beta \mathcal J_{kl}(\ts R,\beta)}{\mathcal J_{kl}(\ts R,\beta)}.
\end{align}
Evaluation of the terms $\delta_\beta \mathcal J_{kl}(\ts R,\beta)$ is straight forvard, and the full expressions becomes
\begin{align}
	\frac{\partial_\beta\mathcal J(\ts R,\beta)}{\mathcal J(\ts R,\beta)}
	=	
	\sum_{k<l}-a_{kl}
	\left( 
		\frac {r_{kl}} {1+\beta r_{kl}}
	\right)^2.
\end{align}

The differention $\partial_\alpha \mathcal D(\ts R,\alpha)$ can be written on the following form: (using partial derivation(???))
\begin{align}
	&\partial_\alpha\mathcal D(\ts R,\alpha)  \notag\\
=&\left|
\begin{matrix}
	& \partial_\alpha\psi_1(\ts r_1,\alpha) & \partial_\alpha\psi_1(\ts r_2,\alpha) & \partial_\alpha\psi_1(\ts r_3,\alpha) &\dots & \\
	& \psi_2(\ts r_1,\alpha) & \psi_2(\ts r_2,\alpha) & \psi_2(\ts r_3,\alpha) & & \\
	& \psi_3(\ts r_1,\alpha) & \psi_3(\ts r_2,\alpha) & \psi_3(\ts r_3,\alpha) & & \\
	& \vdots & & & & % \vdots & \vdots & \vdots & 
\end{matrix}\right|\notag\\
+&\left|
\begin{matrix}
	& \psi_1(\ts r_1,\alpha) & \psi_1(\ts r_2,\alpha) & \psi_1(\ts r_3,\alpha) &\dots & \\
	& \partial_\alpha\psi_2(\ts r_1,\alpha) & \partial_\alpha\psi_2(\ts r_2,\alpha) & \partial_\alpha\psi_2(\ts r_3,\alpha) & & \\
	& \psi_3(\ts r_1,\alpha) & \psi_3(\ts r_2,\alpha) & \psi_3(\ts r_3,\alpha) & & \\
	& \vdots & & & & % \vdots & \vdots & \vdots & 
\end{matrix}
\right|\notag\\
&+\dots \\
&=\mathcal D^{(1)}(\ts r,\alpha)+\mathcal D^{(2)}(\ts r,\alpha)+\dots
\end{align}
Since only one row in the determinant $\mathcal D^{(i)}(\ts R,\alpha)$ is changed, following the same reasoning as in section ?.?, we can write
\begin{align}
&\frac{\mathcal D^{(i)}(\ts R,\alpha)}{\mathcal D(\ts R,\alpha)}=\sum_j(\partial_\alpha \psi_i(\ts r_j,\alpha)) \mathcal D^{-1}_{ji}
\end{align}
giving the expression
\begin{align} 
&\frac{\partial_\alpha \mathcal D(\ts R,\alpha)}{\mathcal D(\ts R,\alpha)}=\sum_i\sum_j(\partial_\alpha \psi_i(\ts r_j,\alpha)) \mathcal D^{-1}_{ji}.
\end{align}
The terms $\partial_\alpha \psi_i(\ts r_j,\alpha)$ are derived below. 
We write $\psi_i(\ts r_j,\alpha)\to\psi_{n_{xi},n_{yi}}(\ts r_j,\alpha)$. where $n_{xi}$ and $n_{yi}$ is quantum numbers equal to or larger than zero. 
%$n_{xi}+n_{yi}\le n_{xj}+n_{yj}$ when $i<j$. 
\begin{align}
	&\psi_{n_{xi},n_{yi}}((x_i,y_i),\alpha)\notag\\
	&=H_{n_{xi}}(\sqrt{\omega\alpha}x_j)H_{n_{xi}}(\sqrt{\omega\alpha}x_j)\psi_{00}((x_i,y_i),\alpha)
\end{align}
$H_n(x)$ is the hermite polynomials.
Differentiation gives
\begin{align}
	&\partial_\alpha\psi_{n_{xi},n_{yi}}((x_i,y_i),\alpha)=\notag\\
	&\bigg(\partial_\alpha H_{n_{xi}}(\sqrt{\omega\alpha}x_j)\bigg)H_{n_{xi}}(\sqrt{\omega\alpha}x_j)\psi_{00}((x_i,y_i),\alpha)\notag\\
	&+H_{n_{xi}}(\sqrt{\omega\alpha}x_j)\bigg(\partial_\alpha H_{n_{xi}}(\sqrt{\omega\alpha}x_j)\bigg)\psi_{00}((x_i,y_i),\alpha)\notag\\
	&+H_{n_{xi}}(\sqrt{\omega\alpha}x_j)H_{n_{xi}}(\sqrt{\omega\alpha}x_j)\bigg(\partial_\alpha \psi_{00}((x_i,y_i),\alpha)\bigg)
	\label{A1}
\end{align}
We make use of the identity $\delta_x H_n(x)=2nH_{n-1}(x)$,
\begin{align}
	\partial_\alpha H_n(\sqrt{\alpha\omega}x)
	&=\frac{\partial H_n(\sqrt{\alpha\omega}x)}{\partial (\sqrt{\alpha\omega}x)} \frac{\partial (\sqrt{\alpha\omega}x)}{\partial\alpha} \notag\\
	&=nx\sqrt{\frac{\omega}{\alpha}} H_{n-1}(\sqrt{\omega\alpha}x)
	\label{A2}
\end{align}
Derivation of $\psi_{00}((x,y),\alpha)$ yields
\begin{align}
	\partial_\alpha \psi_{00}((x,y),\alpha)=
	-\frac\omega2 (x^2+y^2)	
	\psi_{00}((x,y),\alpha).
	\label{A3}
\end{align}
We combine eq. (\ref{A1}), eq. (\ref{A2}) and eq. (\ref{A3})
\begin{align}
	&\partial_\alpha \psi_i(\ts r_j,\alpha)=\notag\\
	&\psi_{n_{xi},n_{yi}}((x_j,y_j),\alpha)
	\bigg(
	 	x_j n_{xi} \sqrt{\frac\omega\alpha} \frac{H_{n_{xi}-1}(\sqrt{\omega\alpha}x_j)}{H_{n_{xi}}(\sqrt{\omega\alpha}x_j)}\notag\\
	 	&+y_j n_{yi} \sqrt{\frac\omega\alpha} \frac{H_{n_{yi}-1}(\sqrt{\omega\alpha}y_j)}{H_{n_{yi}}(\sqrt{\omega\alpha}y_j)}
		-\frac{\omega}2(x_j^2+y_j^2)
	\bigg)
\end{align}

%}}}1

\end{appendix}



%\begin{figure}[h]
%\begin{center}
%	\includegraphics[width=8cm]{../datafiles/4000steps6partw1emin.eps}
%\end{center}
%\caption{{\it\small Example of the path of one walker during 4000 steps. The dotted line shows the path and the crosses 
%marks the samplingpoints}}
%\end{figure}
%
%\begin{figure}[h]
%\begin{center}
%	\includegraphics[width=8cm]{../plots/1pd_2ptdt05emin2e6c.eps}
%\end{center}
%\caption{{\it\small Normalysized densityplot for 2 pt. $\alpha=0.98$, $\omega=0.4$, $\delta t=0.05$. $10^6$ cycles. }}
%\end{figure}
%
%\begin{figure}[h]
%\begin{center}
%	\includegraphics[width=8cm]{../plots/1pd6ptw1emin.eps}
%\end{center}
%\caption{{\it\small Normalized density plot for 6 pt. $\alpha=0.92$, $\omega=0.565$, $\delta t=0.05$. $10^6$ cycles. }}
%\end{figure}
%
%\begin{figure}[h]
%begin{center}
%	\includegraphics[width=8cm]{../plots/1pd_12ptdt05emin2e6c.eps}
%\end{center}
%\caption{{\it\small Normalized density plot for 12 pt. $\alpha=0.87$, $\omega=0.68$, $\delta t=0.05$. $10^6$ cycles. }}
%\end{figure}

\bibliographystyle{plain}	% (uses file "plain.bst")
\bibliography{proj1}		% expects file "proj1.bib"
\end{document}

% vim:foldmethod=marker

